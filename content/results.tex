% $Id: results.tex 
% !TEX root = ../main.tex

\section{Analysis and Results}
\label{sec:results}

This section presents the analysis of the results of the survey presented in \fref{sec:evaluation}. 
This results are presented according to three sections of the survey: General knowledge (\fref{sec:general-knowledge}),
Task Effectiveness (\fref{sec:tasks-results}) and usability (\fref{sec:usability}). Additionally, a 
discussion section is added analyzing the results form the survey. All data obtained from the evaluation is available at our online appendix.\footnote{\url{tbd}} 

%%
\subsection{General Knowledge Results}
\label{sec:general-knowledge}

Most of the participants were very experienced on the use of python as it
can be seen in (\fref{fig:python-experience}), most of the people had a high level of expertise (over 5)
as they used Python very often in their work and university. 
Most of the people were very familiarized using \ac{RL} algorithms (\fref{fig:rl-experience}), as they were 
taking a course on the topic. This is very important information, as the bugs required familiarity with \ac{RL} and python 
knowledge to be identified. Furthermore, the students were very familiarized with 
the terminal, this means it would be easy for them to interact with the tool, as the commands 
and the interface require experience using the terminal (\fref{fig:terminal-experience}). Nevertheless, 
average the 
students weren't familiarized with debuggers, and they only used them very rarely, or used 
Visual Studio Code interface simple features, like breakpoint function. This lead to 
misunderstandings and probably difficulties in making the tasks, as the tool is based on
previous debugger (\fref{fig:debugging-experience}). Also, this made the learning curve of the tool 
steeper than with a person with previous debugger experience.

Note that in the figures in \fref{fig:general-know} the y-axis represents the number of people 
that answered the question with that score, and the x-axis represents score, which could have a 
possible value of 5 being completely agreed, and 1 being completely disagreed.

\begin{figure}[hptb]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/experience-python}
        \caption{Experience using python}
        \label{fig:python-experience}
    \end{subfigure}
    ~ 
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/experience-rl}
        \caption{Experience in \ac{RL}}
        \label{fig:rl-experience}
    \end{subfigure}
    ~ 
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/experience-terminal}
        \caption{Experience using the terminal}
        \label{fig:terminal-experience}
    \end{subfigure}
    ~ 
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/experience-debuggers}
        \caption{Experience in debugging}
        \label{fig:debugging-experience}
    \end{subfigure}
    \caption{Experience reported by users in the four main dimensions of the tools used in the evaluation}
    \label{fig:general-know}
\end{figure}


%%
\subsection{Tasks Results}
\label{sec:tasks-results}

Taking the results reported from the three tasks, most of the developers completed the first task successfully (\fref{fig:task1}). Participants reported the task was easy to solve. Even though the task was reported to be easy, it took participants a long time to complete, because this was the task in which they were getting familiarized with the 
tool. The second task was harder than the first one, most of the people took longer to finish the 
task (\fref{fig:task2}), and most of the people had trouble finding the problem to the program. 
This was meant to be as task 2, wasn't meant to be completely wrong, it was just taking huge 
steps, and the error wasn't because a variable definition, but because a changed in the Q-learning
algorithm, which made a lot of students initially confused. Finally, the third task (\fref{fig:task3}) was the hardest 
one, most people had trouble finding the bug. They thought it wasn't an easy task to solve, 
nevertheless, most of the people managed to finish the task in less time than in the other tasks. 
In this case, it is understandable that for the first task besides being 
easy people took longer, because they were getting familiarized with the tool. For the second task,
given the nature of the bug and the fact that the bug was introduced in the Q-learning algorithm, 
it was harder to find the bug, and for that people thought it was harder to solve, but
most of the people finish it. Finally, for the third task, the bug was introduced in the rewards,
people took less as they had more practice with the tool.

Note that in the figures in \fref{fig:general-know} the y-axis represents the number of people 
that answered the question with that score, and the x-axis represents score, which could have a 
possible value of 5 being completely agreed, and 1 being completely disagreed. Except for the 
last question, in which 5 was taking a lot of time, and 1 was taking very little time.

\begin{figure}[hptb]
    \centering
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/task1}
        \caption{Gridworld task}
        \label{fig:task1}
    \end{subfigure}
    ~ 
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/task2}
        \caption{Rooms task}
        \label{fig:task2}
    \end{subfigure}
    ~ 
    \begin{subfigure}[b]{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/task3}
        \caption{Cars task}
        \label{fig:task3}
    \end{subfigure}
    \caption{Results of the tasks to solve}
    \label{fig:general-know}
\end{figure}


%%
\subsection{Debugger Usability Results}
\label{sec:usability}

Regarding the debugger usability (\fref{tab:general1-debuggers} and \fref{tab:general2-debuggers}), it can 
be seen that the tool was useful,
and the general comments were that the tool would be useful if there was more time to study it. 
And to learn about the tool before using it in real tasks. The 
tool was easy to use, once they got to know it a little better, and they got to practice more with the commands.
Additionally, there were several comments about the tool improving the UI,
as it was hard to understand the tool at first sight, it wasn't similar to the Visual Studio Code 
interface that most of the people were used to use.

Note that in the figures in \fref{fig:general-know} the y-axis represents the number of people 
that answered the question with that score, and the x-axis represents score, which could have a 
possible value of 5 being completely agreed, and 1 being completely disagreed.

\begin{table}[H]
  \centering
  \caption{General Results Part 1}
  \input{tables/usability1}
  \label{tab:general1-debuggers}
\end{table}

\begin{table}[H]
  \centering
  \caption{General Results Part 2}
  \input{tables/usability2}
  \label{tab:general2-debuggers}
\end{table}

% \begin{table}[]
% \centering
% \input{tables/usability3}
% \end{table}

%%
\subsection{Discussion}
\label{sec:discussion}

In general, the results of the survey were very positive, most of the people thought that 
the tool was useful specially for the kind of challenges \ac{RL} programs could have. In 
spite of the tool being hard to familiarized with at the beginning, specially for the people who had very 
little experience with debuggers, most of the people thought that the tool was easy to use 
once you get to know it a little better. Additionally, people said that the tool would've 
been useful for the course development, as most of the main errors they had for their homework,
were related to the bugs being introduced in these tasks.

Additionally, it was expected that for the first task people used a bit more time to finish the 
task, besides being an easy task, as they were getting familiarized with the tool. For the second,
task, most of the people had trouble finding the bug, they needed to explore much more within the 
code before finding the bug, compared to the last task. Finally, it was expected that the developers
took less time to find the last bug, as they already had practice with the tool, and they were 
knew how to use it and how to interact with the program. Nevertheless, it was expected that 
the users felt the task harder than the previous one. It was also surprising that for this last task 
they found more bugs than the initially expected one.


\endinput

